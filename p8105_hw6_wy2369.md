p8105_hw6_wy2369
================
Wenjing Yang
2022-11-29

# Problem 1

# Problem 2

### Read and clean data

Create a `city_state` variable and a `homicide_status` (binary) variable
indicating whether the homicide is solved. Number 0 means “unsolved” and
1 means “solved”

Then omit cities Dallas, TX; Phoenix, AZ; and Kansas City, MO – these
don’t report victim race. Also omit Tulsa, AL – this is a data entry
mistake. Filter whom victim_race is white or black, and convert
`victim_age` to numerical variable. Drop NAs which shown in
`victim_age`.

``` r
homicide_data = 
  read_csv("./data/homicide-data.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    city_state = str_c(city, ",", state),
    victim_age = as.numeric(victim_age),
    homicide_status =  ifelse(disposition != "Closed by arrest", 0, 1)) %>% 
  filter(city_state != "Dallas,TX" & city_state != "Phoenix,AZ" & city_state !="Kansas City,MO" & city_state != "Tulsa,AL") %>% 
  filter(victim_race == "White" | victim_race == "Black") %>% 
  drop_na(victim_age)
```

### Fit a logistic regression for one city

Use the `glm` function to fit a logistic regression with resolved vs
unresolved as the outcome and `victim_age`, `victim_sex` and
`victim_race` as predictors. Save the output of `glm` as an R object and
apply the `broom::tidy` to tidy the data.

``` r
baltimore_reg = 
  homicide_data %>% 
  filter(city_state == "Baltimore,MD") %>% 
  glm(homicide_status ~ victim_age + victim_sex + victim_race, data = ., family = binomial()) %>% 
  broom::tidy() %>% 
  mutate(
    odds_ratio = exp(estimate),
    lower_CI = exp(estimate - 1.96 * std.error),
    upper_CI = exp(estimate + 1.96 * std.error)
  ) %>% 
  filter(term == "victim_sexMale") %>% 
  select(term, estimate, odds_ratio, lower_CI, upper_CI) %>% 
  knitr::kable(digits = 3)

baltimore_reg
```

| term           | estimate | odds_ratio | lower_CI | upper_CI |
|:---------------|---------:|-----------:|---------:|---------:|
| victim_sexMale |   -0.854 |      0.426 |    0.325 |    0.558 |

From the table, I obtain the estimate is **-0.854**，adjusted odds_ratio
is **0.426** and confidence interval is **(0.325, 0.558)** for solving
homicides comparing male victims to female victims keeping all other
variables fixed.

### Fit a logistic regression for each cities

Run `glm` for each of the cities in the dataset and use `map` and
`unnest` functions to create a tidy dataframe with estimates, odds
ratios and confidence intervals for each city.

``` r
homicide_reg = 
  homicide_data %>% 
  nest(data = -city_state) %>% 
  mutate(
    results = map(.x = data ,~glm(homicide_status ~ victim_age + victim_sex + victim_race, data = .x, family = binomial())),
    results = map(results, broom::tidy)) %>% 
  unnest(results) %>%
  mutate(
    odds_ratio = exp(estimate),
    lower_CI = exp(estimate - 1.96 * std.error),
    upper_CI = exp(estimate + 1.96 * std.error)
  ) %>% 
  filter(term == "victim_sexMale") %>% 
  select(city_state, estimate, odds_ratio, lower_CI, upper_CI) 

homicide_reg %>%
  knitr::kable(digits = 3)
```

| city_state        | estimate | odds_ratio | lower_CI | upper_CI |
|:------------------|---------:|-----------:|---------:|---------:|
| Albuquerque,NM    |    0.570 |      1.767 |    0.831 |    3.761 |
| Atlanta,GA        |    0.000 |      1.000 |    0.684 |    1.463 |
| Baltimore,MD      |   -0.854 |      0.426 |    0.325 |    0.558 |
| Baton Rouge,LA    |   -0.964 |      0.381 |    0.209 |    0.695 |
| Birmingham,AL     |   -0.139 |      0.870 |    0.574 |    1.318 |
| Boston,MA         |   -0.395 |      0.674 |    0.356 |    1.276 |
| Buffalo,NY        |   -0.653 |      0.521 |    0.290 |    0.935 |
| Charlotte,NC      |   -0.123 |      0.884 |    0.557 |    1.403 |
| Chicago,IL        |   -0.891 |      0.410 |    0.336 |    0.501 |
| Cincinnati,OH     |   -0.917 |      0.400 |    0.236 |    0.677 |
| Columbus,OH       |   -0.630 |      0.532 |    0.378 |    0.750 |
| Denver,CO         |   -0.736 |      0.479 |    0.236 |    0.971 |
| Detroit,MI        |   -0.541 |      0.582 |    0.462 |    0.734 |
| Durham,NC         |   -0.208 |      0.812 |    0.392 |    1.683 |
| Fort Worth,TX     |   -0.402 |      0.669 |    0.397 |    1.127 |
| Fresno,CA         |    0.289 |      1.335 |    0.580 |    3.071 |
| Houston,TX        |   -0.341 |      0.711 |    0.558 |    0.907 |
| Indianapolis,IN   |   -0.085 |      0.919 |    0.679 |    1.242 |
| Jacksonville,FL   |   -0.329 |      0.720 |    0.537 |    0.966 |
| Las Vegas,NV      |   -0.178 |      0.837 |    0.608 |    1.154 |
| Long Beach,CA     |   -0.891 |      0.410 |    0.156 |    1.082 |
| Los Angeles,CA    |   -0.413 |      0.662 |    0.458 |    0.956 |
| Louisville,KY     |   -0.712 |      0.491 |    0.305 |    0.790 |
| Memphis,TN        |   -0.324 |      0.723 |    0.529 |    0.988 |
| Miami,FL          |   -0.663 |      0.515 |    0.304 |    0.872 |
| Milwaukee,wI      |   -0.319 |      0.727 |    0.499 |    1.060 |
| Minneapolis,MN    |   -0.054 |      0.947 |    0.478 |    1.875 |
| Nashville,TN      |    0.034 |      1.034 |    0.685 |    1.562 |
| New Orleans,LA    |   -0.536 |      0.585 |    0.422 |    0.811 |
| New York,NY       |   -1.338 |      0.262 |    0.138 |    0.499 |
| Oakland,CA        |   -0.574 |      0.563 |    0.365 |    0.868 |
| Oklahoma City,OK  |   -0.026 |      0.974 |    0.624 |    1.520 |
| Omaha,NE          |   -0.961 |      0.382 |    0.203 |    0.721 |
| Philadelphia,PA   |   -0.701 |      0.496 |    0.378 |    0.652 |
| Pittsburgh,PA     |   -0.842 |      0.431 |    0.265 |    0.700 |
| Richmond,VA       |    0.006 |      1.006 |    0.498 |    2.033 |
| San Antonio,TX    |   -0.350 |      0.705 |    0.398 |    1.249 |
| Sacramento,CA     |   -0.402 |      0.669 |    0.335 |    1.337 |
| Savannah,GA       |   -0.143 |      0.867 |    0.422 |    1.780 |
| San Bernardino,CA |   -0.692 |      0.500 |    0.171 |    1.462 |
| San Diego,CA      |   -0.884 |      0.413 |    0.200 |    0.855 |
| San Francisco,CA  |   -0.498 |      0.608 |    0.317 |    1.165 |
| St. Louis,MO      |   -0.352 |      0.703 |    0.530 |    0.932 |
| Stockton,CA       |    0.301 |      1.352 |    0.621 |    2.942 |
| Tampa,FL          |   -0.214 |      0.808 |    0.348 |    1.876 |
| Tulsa,OK          |   -0.025 |      0.976 |    0.614 |    1.552 |
| Washington,DC     |   -0.371 |      0.690 |    0.468 |    1.017 |

### Create a plot

The plot shows the estimated odds ratios and confidence intervals for
each city.

``` r
homicide_reg %>%
  ggplot(aes(x = fct_reorder(city_state,odds_ratio), y = odds_ratio)) +
  geom_point() +
  geom_errorbar(aes(ymin = lower_CI, ymax = upper_CI)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(title = "The estimated odds ratios and confidence intervals for each city",
       x = "City, State",
       y = "Estimated odds ratios") 
```

<img src="p8105_hw6_wy2369_files/figure-gfm/unnamed-chunk-5-1.png" width="90%" />

comment on the plot.

# Problem 3

### Load and clean data

Load and clean the data and check for missing data using this code
chunk.

``` r
birthweight_data = 
  read_csv("./data/birthweight.csv") %>% 
  janitor::clean_names() 
```

    ## Rows: 4342 Columns: 20
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (20): babysex, bhead, blength, bwt, delwt, fincome, frace, gaweeks, malf...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
skimr::skim(birthweight_data)
```

|                                                  |                  |
|:-------------------------------------------------|:-----------------|
| Name                                             | birthweight_data |
| Number of rows                                   | 4342             |
| Number of columns                                | 20               |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_   |                  |
| Column type frequency:                           |                  |
| numeric                                          | 20               |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ |                  |
| Group variables                                  | None             |

Data summary

**Variable type: numeric**

| skim_variable | n_missing | complete_rate |    mean |     sd |     p0 |     p25 |     p50 |     p75 |   p100 | hist  |
|:--------------|----------:|--------------:|--------:|-------:|-------:|--------:|--------:|--------:|-------:|:------|
| babysex       |         0 |             1 |    1.49 |   0.50 |   1.00 |    1.00 |    1.00 |    2.00 |    2.0 | ▇▁▁▁▇ |
| bhead         |         0 |             1 |   33.65 |   1.62 |  21.00 |   33.00 |   34.00 |   35.00 |   41.0 | ▁▁▆▇▁ |
| blength       |         0 |             1 |   49.75 |   2.72 |  20.00 |   48.00 |   50.00 |   51.00 |   63.0 | ▁▁▁▇▁ |
| bwt           |         0 |             1 | 3114.40 | 512.15 | 595.00 | 2807.00 | 3132.50 | 3459.00 | 4791.0 | ▁▁▇▇▁ |
| delwt         |         0 |             1 |  145.57 |  22.21 |  86.00 |  131.00 |  143.00 |  157.00 |  334.0 | ▅▇▁▁▁ |
| fincome       |         0 |             1 |   44.11 |  25.98 |   0.00 |   25.00 |   35.00 |   65.00 |   96.0 | ▃▇▅▂▃ |
| frace         |         0 |             1 |    1.66 |   0.85 |   1.00 |    1.00 |    2.00 |    2.00 |    8.0 | ▇▁▁▁▁ |
| gaweeks       |         0 |             1 |   39.43 |   3.15 |  17.70 |   38.30 |   39.90 |   41.10 |   51.3 | ▁▁▂▇▁ |
| malform       |         0 |             1 |    0.00 |   0.06 |   0.00 |    0.00 |    0.00 |    0.00 |    1.0 | ▇▁▁▁▁ |
| menarche      |         0 |             1 |   12.51 |   1.48 |   0.00 |   12.00 |   12.00 |   13.00 |   19.0 | ▁▁▂▇▁ |
| mheight       |         0 |             1 |   63.49 |   2.66 |  48.00 |   62.00 |   63.00 |   65.00 |   77.0 | ▁▁▇▂▁ |
| momage        |         0 |             1 |   20.30 |   3.88 |  12.00 |   18.00 |   20.00 |   22.00 |   44.0 | ▅▇▂▁▁ |
| mrace         |         0 |             1 |    1.63 |   0.77 |   1.00 |    1.00 |    2.00 |    2.00 |    4.0 | ▇▇▁▁▁ |
| parity        |         0 |             1 |    0.00 |   0.10 |   0.00 |    0.00 |    0.00 |    0.00 |    6.0 | ▇▁▁▁▁ |
| pnumlbw       |         0 |             1 |    0.00 |   0.00 |   0.00 |    0.00 |    0.00 |    0.00 |    0.0 | ▁▁▇▁▁ |
| pnumsga       |         0 |             1 |    0.00 |   0.00 |   0.00 |    0.00 |    0.00 |    0.00 |    0.0 | ▁▁▇▁▁ |
| ppbmi         |         0 |             1 |   21.57 |   3.18 |  13.07 |   19.53 |   21.03 |   22.91 |   46.1 | ▃▇▁▁▁ |
| ppwt          |         0 |             1 |  123.49 |  20.16 |  70.00 |  110.00 |  120.00 |  134.00 |  287.0 | ▅▇▁▁▁ |
| smoken        |         0 |             1 |    4.15 |   7.41 |   0.00 |    0.00 |    0.00 |    5.00 |   60.0 | ▇▁▁▁▁ |
| wtgain        |         0 |             1 |   22.08 |  10.94 | -46.00 |   15.00 |   22.00 |   28.00 |   89.0 | ▁▁▇▁▁ |

Based on these results, there is no missing data in this dataset and 20
variables are all numeric.
